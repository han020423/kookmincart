#!/usr/bin/env python
# -*- coding: utf-8 -*-
#=============================================
# ë³¸ í”„ë¡œê·¸ë¨ì€ 2025 ì œ8íšŒ êµ­ë¯¼ëŒ€ ììœ¨ì£¼í–‰ ê²½ì§„ëŒ€íšŒì—ì„œ
# ì˜ˆì„ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ íŒŒì¼ì…ë‹ˆë‹¤.
# ì˜ˆì„ ê³¼ì œ ìˆ˜í–‰ ìš©ë„ë¡œë§Œ ì‚¬ìš©ê°€ëŠ¥í•˜ë©° ì™¸ë¶€ìœ ì¶œì€ ê¸ˆì§€ë©ë‹ˆë‹¤.
#=============================================
# í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” ê°ì¢… íŒŒì´ì¬ íŒ¨í‚¤ì§€ë“¤ì˜ import ì„ ì–¸ë¶€
#=============================================
import numpy as np
import cv2, rospy, time, os, math
from sensor_msgs.msg import Image
from xycar_msgs.msg import XycarMotor
from cv_bridge import CvBridge
from sensor_msgs.msg import LaserScan
import matplotlib.pyplot as plt

#=============================================
# í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜, ì €ì¥ê³µê°„ ì„ ì–¸ë¶€
#=============================================
image = np.empty(shape=[0])  # ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë‹´ì„ ë³€ìˆ˜
ranges = None  # ë¼ì´ë‹¤ ë°ì´í„°ë¥¼ ë‹´ì„ ë³€ìˆ˜
motor = None  # ëª¨í„° ì œì–´ ROS Publisher
motor_msg = XycarMotor()  # ëª¨í„° í† í”½ ë©”ì‹œì§€
bridge = CvBridge()  # OpenCV í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¸Œë¦¿ì§€

# ì£¼í–‰ ìƒíƒœ ê´€ë ¨ ë³€ìˆ˜
current_mission_state = "WAITING_FOR_GREEN_LIGHT"
# ì°¨ëŸ‰ ì œì–´ ìƒìˆ˜
Fix_Speed = 60  # ê¸°ë³¸ ì£¼í–‰ ì†ë„
Slow_Speed = 20
Min_Speed = 5   # ìµœì†Œ ì£¼í–‰ ì†ë„ (ì˜ˆ: ì¥ì• ë¬¼ íšŒí”¼ ì‹œ)
Max_Speed = 100  # ìµœëŒ€ ì£¼í–‰ ì†ë„
Angle_Limit = 75 # ìµœëŒ€ ì¡°í–¥ê°
prev_angle = 0.0 #ì´ì „ ì¡°í–¥ê°
last_avoidance_time = 0  # ë§ˆì§€ë§‰ ì°¨ì„ ë³€ê²½ ì‹œê° ì €ì¥ìš© (ì´ˆ)
AVOIDANCE_COOLDOWN = 8   # ì¿¨íƒ€ì„ (ì´ˆ)

# ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ë³€ìˆ˜
TRAFFIC_LIGHT_ROI_INITIAL = (280, 100, 80, 150) 
# HSV ìƒ‰ìƒ ë²”ìœ„ (Green, Yellow, Red)
GREEN_LOWER = np.array([40, 80, 80])
GREEN_UPPER = np.array([90, 255, 255])
YELLOW_LOWER = np.array([20, 100, 100])
YELLOW_UPPER = np.array([30, 255, 255])
RED_LOWER1 = np.array([0, 100, 100]) 
RED_UPPER1 = np.array([10, 255, 255])
RED_LOWER2 = np.array([170, 100, 100])
RED_UPPER2 = np.array([180, 255, 255])

# ì°¨ì„  ê°ì§€ ROI 
LANE_ROI_VERT_PERCENT_START = 0.6 
LANE_ROI_VERT_PERCENT_END = 0.95   

#=============================================
# ë¼ì´ë‹¤ ìŠ¤ìº”ì •ë³´ë¡œ ê·¸ë¦¼ì„ ê·¸ë¦¬ê¸° ìœ„í•œ ë³€ìˆ˜ (ë””ë²„ê¹…ìš©)
#=============================================
fig, ax = plt.subplots(figsize=(8, 8))
ax.set_xlim(-10, 10) #LIDAR ìµœëŒ€ ê°ì§€ ê±°ë¦¬ê°€ 100m ì´ë‚˜, ì‹¤ì œ ì£¼í–‰ì— ì¤‘ìš”í•œ ì˜ì—­ ìœ„ì£¼ë¡œ í‘œì‹œ
ax.set_ylim(-10, 10)
ax.set_aspect('equal')
lidar_points, = ax.plot([], [], 'bo', markersize=2)

#=============================================
# ì½œë°±í•¨ìˆ˜ - ì¹´ë©”ë¼ í† í”½ì„ ì²˜ë¦¬í•˜ëŠ” ì½œë°±í•¨ìˆ˜
# ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ image ë³€ìˆ˜ì— ì €ì¥
#=============================================
def usbcam_callback(data):
    global image
    image = bridge.imgmsg_to_cv2(data, "bgr8") # ROS Image ë©”ì‹œì§€ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜

#=============================================
# ì½œë°±í•¨ìˆ˜ - ë¼ì´ë‹¤ í† í”½ì„ ë°›ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” ì½œë°±í•¨ìˆ˜
# ë¼ì´ë‹¤ ë°ì´í„°ë¥¼ ë°›ì•„ ranges ë³€ìˆ˜ì— ì €ì¥
#=============================================
def lidar_callback(data):
    global ranges
    ranges = np.array(data.ranges)

#=============================================
# ëª¨í„°ë¡œ í† í”½ì„ ë°œí–‰í•˜ëŠ” í•¨ìˆ˜
# ì£¼ì–´ì§„ ê°ë„(angle)ì™€ ì†ë„(speed)ë¡œ ì°¨ëŸ‰ì„ ì œì–´
#=============================================
def drive(angle, speed):
    motor_msg.angle = max(min(float(angle), Angle_Limit), -Angle_Limit)
    motor_msg.speed = max(min(float(speed), Max_Speed), -Max_Speed)
    motor.publish(motor_msg)

#=============================================
# ì‹ í˜¸ë“± ì¸ì‹ í•¨ìˆ˜
# ì…ë ¥: í˜„ì¬ ì¹´ë©”ë¼ ì´ë¯¸ì§€ (BGR)
# ì¶œë ¥: "RED", "YELLOW", "GREEN", ë˜ëŠ” "NONE"
#=============================================
def detect_traffic_light(current_image):
    if current_image.size == 0:
        return "NONE"

    height, width = current_image.shape[:2]
    x, y, w, h = int(width*0.2), int(height*0.05), int(width*0.6), int(height*0.2)

    x = max(0, x)
    y = max(0, y)
    w = min(w, width - x)
    h = min(h, height - y)
    
    if w <= 0 or h <= 0:
        return "NONE" 

    roi = current_image[y:y+h, x:x+w]

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    # 3. ìƒ‰ìƒ ë§ˆìŠ¤í¬ ìƒì„± ë° ë¹› ê°ì§€
    # ê° ìƒ‰ìƒ(ë¹¨ê°•, ë…¸ë‘, ì´ˆë¡)ì— ëŒ€í•œ ë§ˆìŠ¤í¬ ìƒì„±
    mask_green = cv2.inRange(hsv, GREEN_LOWER, GREEN_UPPER)
    mask_yellow = cv2.inRange(hsv, YELLOW_LOWER, YELLOW_UPPER)
    mask_red1 = cv2.inRange(hsv, RED_LOWER1, RED_UPPER1)
    mask_red2 = cv2.inRange(hsv, RED_LOWER2, RED_UPPER2)
    mask_red = cv2.bitwise_or(mask_red1, mask_red2)

    # 4. ê°€ì¥ ë‘ë“œëŸ¬ì§€ëŠ” ìƒ‰ìƒ íŒë‹¨
    # ê° ë§ˆìŠ¤í¬ì—ì„œ 0ì´ ì•„ë‹Œ í”½ì…€ ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì–´ë–¤ ìƒ‰ì´ ê°€ì¥ ë§ì´ ê²€ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
    green_pixels = cv2.countNonZero(mask_green)
    yellow_pixels = cv2.countNonZero(mask_yellow)
    red_pixels = cv2.countNonZero(mask_red)
    
    # cv2.imshow("Traffic Light ROI", roi) # ë””ë²„ê¹…ìš©
    # cv2.imshow("Green Mask", mask_green) # ë””ë²„ê¹…ìš©

    # ì„ê³„ê°’ ì„¤ì • 
    min_pixel_threshold = 50 
    if green_pixels > min_pixel_threshold and green_pixels > yellow_pixels and green_pixels > red_pixels:
        # print("Traffic Light: GREEN")
        return "GREEN"
    elif yellow_pixels > min_pixel_threshold and yellow_pixels > green_pixels and yellow_pixels > red_pixels:
        # print("Traffic Light: YELLOW")
        return "YELLOW"
    elif red_pixels > min_pixel_threshold and red_pixels > green_pixels and red_pixels > yellow_pixels:
        # print("Traffic Light: RED")
        return "RED"
    
    return "NONE" 


#=============================================
# ì°¨ëŸ‰ ìœ„ì¹˜ íŒë‹¨
#=============================================
def detect_yellow_lane_side(image, left_lines, right_lines):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    yellow_range = (15, 50)  # Hue ê¸°ì¤€

    def yellow_ratio_along_lines(lines):
        yellow_count = 0
        total_count = 0

        for x1, y1, x2, y2 in lines:
            num_points = 10
            for i in range(num_points):
                x = int(x1 + (x2 - x1) * i / (num_points - 1))
                y = int(y1 + (y2 - y1) * i / (num_points - 1))
                if 0 <= x < hsv.shape[1] and 0 <= y < hsv.shape[0]:
                    hue = hsv[y, x, 0]
                    if yellow_range[0] <= hue <= yellow_range[1]:
                        yellow_count += 1
                    total_count += 1

        if total_count == 0:
            return 0.0
        return yellow_count / total_count

    left_yellow_ratio = yellow_ratio_along_lines(left_lines)
    right_yellow_ratio = yellow_ratio_along_lines(right_lines)

    # print(f"[Hue ë¶„ì„] ì™¼ìª½ ë…¸ë€ìƒ‰ ë¹„ìœ¨: {left_yellow_ratio:.2f}, ì˜¤ë¥¸ìª½: {right_yellow_ratio:.2f}")

    if left_yellow_ratio > right_yellow_ratio and left_yellow_ratio > 0.1:
        return "Right Lane"  # ì¤‘ì•™ì„ ì´ ì™¼ìª½ì— ìˆìŒ â†’ ìš°ì¸¡ ì°¨ì„  ì£¼í–‰ ì¤‘
    elif right_yellow_ratio > left_yellow_ratio and right_yellow_ratio > 0.1:
        return "Left Lane"   # ì¤‘ì•™ì„ ì´ ì˜¤ë¥¸ìª½ì— ìˆìŒ â†’ ì¢Œì¸¡ ì°¨ì„  ì£¼í–‰ ì¤‘
    else:
        return "Unknown"


#=============================================
# ì°¨ì„  ì¸ì‹ ë° ì¡°í–¥ê° ê³„ì‚° í•¨ìˆ˜
# ì…ë ¥: í˜„ì¬ ì¹´ë©”ë¼ ì´ë¯¸ì§€
# ì¶œë ¥: ê³„ì‚°ëœ ì¡°í–¥ê° 
#=============================================
def calculate_lane_steering(current_image):
    if current_image.size == 0:
        return 0.0

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ 
    height, width = current_image.shape[:2]
    gray = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)

    # ROI ì„¤ì •: í™”ë©´ í•˜ë‹¨ ì˜ì—­ë§Œ ì‚¬ìš©
    roi_start_y = int(height * LANE_ROI_VERT_PERCENT_START)
    roi_end_y = int(height * LANE_ROI_VERT_PERCENT_END)

    roi_mask = np.zeros_like(blur)
    poly_vertices = np.array([[(0, roi_end_y), (width*0.1, roi_start_y), (width*0.9, roi_start_y), (width, roi_end_y)]], dtype=np.int32)
    cv2.fillPoly(roi_mask, poly_vertices, 255)
    
    masked_image = cv2.bitwise_and(blur, roi_mask)
    #cv2.imshow("Lane ROI", masked_image) # ë””ë²„ê¹…ìš©

    edges = cv2.Canny(masked_image, 70, 140)
    # cv2.imshow("Lane Edges", edges) # ë””ë²„ê¹…ìš©

    # í—ˆí”„ ë³€í™˜ ì„ ë¶„ ê²€ì¶œ
    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=30, minLineLength=20, maxLineGap=20) 

    if lines is None:
        return 0.0 # ì°¨ì„  ë¯¸ê²€ì¶œ ì‹œ ì§ì§„

    # ê²€ì¶œëœ ì„ ë“¤ì„ ì´ìš©í•´ ì¢Œ/ìš° ì°¨ì„  ëŒ€í‘œì„  ê³„ì‚° ë° í™”ë©´ ì¤‘ì•™ê³¼ì˜ ì˜¤ì°¨ ê³„ì‚°
    # í™”ë©´ ì¤‘ì•™ê³¼ ì°¨ì„  ì¤‘ì•™ ê°„ì˜ ì°¨ì´ ê³„ì‚°í•´  ë¹„ë¡€í•˜ëŠ” ì¡°í–¥ê°ì„ ì„¤ì •
    left_lines, right_lines = [], []
    for line in lines:
        x1, y1, x2, y2 = line[0]
        if x2 - x1 == 0:
            slope = np.inf
        else:
            slope = (y2 - y1) / (x2 - x1)
        
        if slope < -0.3: # ì¢Œì¸¡ ì°¨ì„  
            left_lines.append(line[0])
        elif slope > 0.3: # ìš°ì¸¡ ì°¨ì„  
            right_lines.append(line[0])


    # ëŒ€í‘œì„  ê³„ì‚°
    # ì¢Œì¸¡ ì°¨ì„ ì´ ì¸ì‹ëœ ê²½ìš°
    if left_lines:
        left_x_coords = []
        for x1,y1,x2,y2 in left_lines:
            left_x_coords.extend([x1,x2])
        avg_left_x = np.mean(left_x_coords)
    else: 
        avg_left_x = width * 0.1 

    # ìš°ì¸¡ ì°¨ì„ ì´ ì¸ì‹ëœ ê²½ìš°
    if right_lines:
        right_x_coords = []
        for x1,y1,x2,y2 in right_lines:
            right_x_coords.extend([x1,x2])
        avg_right_x = np.mean(right_x_coords)
    else: 
        avg_right_x = width * 0.9

    lane_center_x = (avg_left_x + avg_right_x) / 2.0
    car_center_x = width / 2.0
    
    error = lane_center_x - car_center_x

    # ì¡°í–¥ê° ê³„ì‚° 
    Kp = 0.4 
    steering_angle = Kp * error
    

    debug_image = current_image.copy()
    # ì¢Œì¸¡ ì°¨ì„  ì„ ë¶„ì€ íŒŒë€ìƒ‰
    for x1, y1, x2, y2 in left_lines:
        cv2.line(current_image, (x1, y1), (x2, y2), (255, 0, 0), 2) 
    # ìš°ì¸¡ ì°¨ì„  ì„ ë¶„ì€ ë¹¨ê°„ìƒ‰ìƒ‰
    for x1, y1, x2, y2 in right_lines:
        cv2.line(current_image, (x1, y1), (x2, y2), (0, 0, 255), 2) 

    # ROI ì„  ì‹œê°í™”
    cv2.polylines(current_image, [poly_vertices], isClosed=True, color=(0, 255, 0), thickness=2)


    # ìƒ‰ìƒ ë¶„ì„ 
    lane_position = detect_yellow_lane_side(debug_image, left_lines, right_lines)
 
    return steering_angle, lane_position


def visualize_yellow_area(image_bgr):
    hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
    hue = hsv[:, :, 0]
    yellow_mask = cv2.inRange(hue, 15, 50)

    yellow_highlight = image_bgr.copy()
    yellow_highlight[yellow_mask > 0] = [0, 0, 255]
    cv2.imshow("Yellow Lane Highlight", yellow_highlight)
    cv2.waitKey(1)


#=============================================
# ë¼ë°”ì½˜ ê°ì§€
#=============================================
def detect_cone_presence(current_image, lidar_data):
    if lidar_data is None or current_image.size == 0:
        return False

    # 1. LiDAR ê¸°ì¤€ ìœ íš¨í•œ ê±°ë¦¬ê°’ ì¶”ì¶œ
    front_left = lidar_data[340:]
    front_right = lidar_data[:21]
    front_scan = np.concatenate((front_left, front_right))
    front_scan = np.array(front_scan)
    valid_lidar = front_scan[np.isfinite(front_scan) & (front_scan > 0.5) & (front_scan < 10.0)]

    # 2. 5ê°œ ì´ìƒ ê°ì§€ëœ ê²½ìš°ì—ë§Œ ì¹´ë©”ë¼ íŒë‹¨ ìˆ˜í–‰
    if len(valid_lidar) < 4:
        return False

    height = current_image.shape[0]
    roi = current_image[int(height * 0.6):, :]

    # 3. ì¹´ë©”ë¼ì—ì„œ ë¼ë°”ì½˜ ìƒ‰ìƒ(Hue â‰ˆ 8) í•„í„°ë§
    hsv = cv2.cvtColor(current_image, cv2.COLOR_BGR2HSV)
    LOWER_CONE = np.array([5, 80, 150])
    UPPER_CONE = np.array([15, 255, 255])
    mask = cv2.inRange(hsv, LOWER_CONE, UPPER_CONE)

    # 4. ì—£ì§€(ìœ¤ê³½ì„ ) ê²€ì¶œ
    edges = cv2.Canny(mask, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # 5. ì¼ì • í¬ê¸° ì´ìƒì˜ ìœ¤ê³½ì„ ì´ ì¡´ì¬í•˜ë©´ ë¼ë°”ì½˜ìœ¼ë¡œ íŒë‹¨
    for cnt in contours:
        if cv2.contourArea(cnt) > 100:  
            return True

    return False

def detect_cones_only_camera(image):
    height, width = image.shape[:2]
    roi = image[int(height * 0.6):, :]  # í•˜ë‹¨ 40% ì‚¬ìš©
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    LOWER_CONE = np.array([5, 80, 150])
    UPPER_CONE = np.array([15, 255, 255])
    mask = cv2.inRange(hsv, LOWER_CONE, UPPER_CONE)

    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # ì¼ì • í¬ê¸° ì´ìƒì˜ ë¼ë°”ì½˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    return any(cv2.contourArea(cnt) > 100 for cnt in contours)


#=============================================
# ë¼ë°”ì½˜ ì£¼í–‰
#=============================================
def calculate_cone_steering_camera(image, prev_angle=0, debug=False):

    if image is None or image.size == 0:
        return prev_angle

    height, width = image.shape[:2]
    roi_start = int(height * 0.7)
    roi = image[roi_start:, :]

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    LOWER_ORANGE = np.array([5, 100, 100])
    UPPER_ORANGE = np.array([20, 255, 255])
    mask = cv2.inRange(hsv, LOWER_ORANGE, UPPER_ORANGE)

    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    centers = []

    # ì¤‘ì•™ ë¬´ì‹œ ì˜ì—­ ì •ì˜ (45%~55%)
    center_ignore_min = int(width * 0.5)
    center_ignore_max = int(width * 0.5)

    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 150:
            M = cv2.moments(cnt)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                # ì¤‘ì•™ ì˜ì—­ ë¬´ì‹œ
                if center_ignore_min <= cx <= center_ignore_max:
                    continue
                centers.append((cx, cy))

    vis = roi.copy()
    left = []
    right = []
    for cx, cy in centers:
        if cx < width // 2:
            left.append(cx)
            cv2.circle(vis, (cx, cy), 5, (255, 0, 0), -1)
        else:
            right.append(cx)
            cv2.circle(vis, (cx, cy), 5, (0, 0, 255), -1)


    angle = prev_angle

    if len(left) > 0 and len(right) > 0:
        left_x = min(left)
        right_x = max(right)
        gap = right_x - left_x

        if gap < 350:
            if debug: print(f"[CAMERA] ë¼ë°”ì½˜ ê°„ê²© {gap}px < 350 â†’ ì´ì „ ê°ë„ ìœ ì§€")
        else:
            mid_x = (left_x + right_x) // 2
            error = mid_x - width // 2
            angle = np.clip(0.6 * error, -40, 40)
            if debug:
                print(f"[CAMERA] ì¤‘ì•™: {mid_x}, ê°„ê²©: {gap}, ì¡°í–¥: {angle:.2f}")
                cv2.line(vis, (mid_x, 0), (mid_x, vis.shape[0]), (0, 255, 0), 2)
                cv2.line(vis, (width // 2, 0), (width // 2, vis.shape[0]), (0, 255, 255), 2)

    elif len(left) > 0:
        left_x = min(left)
        angle = 75
        if debug: print("[CAMERA] ì™¼ìª½ ë¼ë°”ì½˜ë§Œ ê°ì§€ â†’ ìš°íšŒì „")

    elif len(right) > 0:
        right_x = max(right)
        angle = -75
        if debug: print("[CAMERA] ì˜¤ë¥¸ìª½ ë¼ë°”ì½˜ë§Œ ê°ì§€ â†’ ì¢ŒíšŒì „")

    else:
        if debug: print("[CAMERA] ë¼ë°”ì½˜ ì—†ìŒ â†’ ì´ì „ ê°ë„ ìœ ì§€")

    if debug:
        cv2.imshow("Cone Detection (camera)", vis)
        cv2.rectangle(vis, (center_ignore_min, 0), (center_ignore_max, vis.shape[0]), (0, 255, 255), 2)
        cv2.waitKey(1)

    return angle



#=============================================
# ì°¨ëŸ‰ íŒë‹¨ í•¨ìˆ˜
#=============================================
def detect_vehicle_front(lidar_data):
    if lidar_data is None or len(lidar_data) < 360:
        return "CLEAR"

    front_left = lidar_data[355:]
    front_right = lidar_data[:6]
    front_scan = np.concatenate((front_left, front_right))

    front_scan = np.array(front_scan)
    valid = front_scan[np.isfinite(front_scan) & (front_scan > 1.0) & (front_scan < 20.0)]

    if len(valid) == 0:
        return "CLEAR"

    # ì—°ì† ê°ì§€ êµ¬ê°„ ê³„ì‚°
    close_flags = (front_scan > 1.0) & (front_scan < 20.0)
    consecutive_count = 0
    max_consecutive = 0

    for val in close_flags:
        if val:
            consecutive_count += 1
            max_consecutive = max(max_consecutive, consecutive_count)
        else:
            consecutive_count = 0

    print(f"[ì „ë°© ê°ì§€] ìœ íš¨ ê±°ë¦¬ {len(valid)}ê°œ / ì—°ì† {max_consecutive}ê°œ")

    # ğŸš— ì°¨ëŸ‰ìœ¼ë¡œ íŒë‹¨ (ì™„ì „ ì •ì§€)
    if max_consecutive >= 8:
        return "STOP"

    # ğŸ¢ ê°ì§€ëŠ” ëì§€ë§Œ í™•ì‹  ë¶€ì¡± (ê°ì†)
    elif len(valid) >= 5:
        return "SLOW"

    return "CLEAR"

#=============================================
# ë©”ì¸ í•¨ìˆ˜
#=============================================
def start():
    global motor, image, ranges, current_mission_state, prev_angle, last_avoidance_time
    lane_position = "Unknown"
    print("Start program --------------")

    #=========================================
    # ë…¸ë“œë¥¼ ìƒì„±í•˜ê³ , êµ¬ë…/ë°œí–‰í•  í† í”½ë“¤ì„ ì„ ì–¸í•©ë‹ˆë‹¤.
    #=========================================
    rospy.init_node('Track_Driver')
    rospy.Subscriber("/usb_cam/image_raw/",Image,usbcam_callback, queue_size=1)
    rospy.Subscriber("/scan", LaserScan, lidar_callback, queue_size=1)
    motor = rospy.Publisher('xycar_motor', XycarMotor, queue_size=1)
        
    #=========================================
    # ë…¸ë“œë“¤ë¡œë¶€í„° ì²«ë²ˆì§¸ í† í”½ë“¤ì´ ë„ì°©í•  ë•Œê¹Œì§€ ëŒ€ê¸°
    #=========================================
    print("Waiting for first messages...")
    rospy.wait_for_message("/usb_cam/image_raw/", Image) 
    print("Camera Ready --------------")
    rospy.wait_for_message("/scan", LaserScan) 
    print("Lidar Ready --------------")
    
    #=========================================
    # ë¼ì´ë‹¤ ìŠ¤ìº”ì •ë³´ ì‹œê°í™” ì¤€ë¹„
    #=========================================
    if 'matplotlib' in sys.modules: 
        plt.ion()
        plt.show()
        print("Lidar Visualizer Ready (matplotlib) ----------")
    else:
        print("Matplotlib not available for Lidar visualization.")

    
    print("======================================")
    print(" S T A R T    D R I V I N G ...")
    print("======================================")

    #=========================================
    # ë©”ì¸ ë£¨í”„ 
    # ë£¨í”„ ì£¼ê¸° ì„¤ì •
    #=========================================
    loop_rate = rospy.Rate(10)

    while not rospy.is_shutdown():
        # í˜„ì¬ ì´ë¯¸ì§€ì™€ ë¼ì´ë‹¤ ë°ì´í„° ë³µì‚¬
        current_image_data = image.copy()
        current_lidar_data = ranges.copy() if ranges is not None else None

        # ì¡°í–¥ê°ê³¼ ì†ë„ ì´ˆê¸°í™”
        target_angle = 0.0
        target_speed = 0.0

        # ========================================
        # ì£¼í–‰ ìƒíƒœì— ë”°ë¥¸ ë¡œì§ ë¶„ê¸°
        # ========================================
        if current_mission_state == "WAITING_FOR_GREEN_LIGHT":
            # ì‹ í˜¸ë“±ì´ ë…¹ìƒ‰ì´ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            traffic_light_color = detect_traffic_light(current_image_data)
            # print(f"STATE: WAITING_FOR_GREEN_LIGHT, Detected: {traffic_light_color}")
            if traffic_light_color == "GREEN":
                print("Green light detected! Starting lane following.")
                current_mission_state = "LANE_FOLLOWING"
                target_speed = Fix_Speed # ì¶œë°œ ì†ë„
            elif traffic_light_color == "YELLOW" or traffic_light_color == "RED":
                target_speed = 0 
            else: 
                target_speed = 0 

        elif current_mission_state == "LANE_FOLLOWING":
            # ì°¨ì„  ì£¼í–‰ ë¡œì§
            # print("STATE: LANE_FOLLOWING")
            target_angle, lane_position = calculate_lane_steering(current_image_data)
            target_speed = Fix_Speed

            # ë¼ë°”ì½˜ ê°ì§€ ì‹œ ìƒíƒœ ì „í™˜
            if detect_cone_presence(current_image_data, current_lidar_data):
                print("[STATE] ğŸŸ§ ë¼ë°”ì½˜ ì¸ì‹ë¨ â†’ ìƒíƒœ ì „í™˜: CONE_NAVIGATION")
                current_mission_state = "CONE_NAVIGATION"

            # ì°¨ëŸ‰ ê°ì§€ ì¡°ê±´
            if current_lidar_data is not None:
                obstacle_state = detect_vehicle_front(current_lidar_data)
                if obstacle_state == "STOP":
                        # ì¿¨íƒ€ì„ ì²´í¬
                    if time.time() - last_avoidance_time < AVOIDANCE_COOLDOWN:
                        print("[â³ ì¿¨íƒ€ì„] ìµœê·¼ íšŒí”¼ ì´í›„ ëŒ€ê¸° ì¤‘ â†’ ì°¨ì„  ìœ ì§€")
                        continue  # ìƒíƒœ ì „í™˜ ì•ˆ í•˜ê³  ì°¨ì„  ìœ ì§€

                    print("[STATE] ğŸš— ì°¨ëŸ‰ ê°ì§€ â†’ ì°¨ì„ ë³€ê²½")

                    if lane_position == "Left Lane":
                        avoidance_direction = "RIGHT"
                    elif lane_position == "Right Lane":
                        avoidance_direction = "LEFT"
                    else:
                        # ì°¨ì„  ì •ë³´ ë¶ˆë¶„ëª… ì‹œ ê¸°ë³¸ íšŒí”¼ ë°©í–¥ ì„¤ì •
                        avoidance_direction = "RIGHT"


                    # # ì°¨ì„  ë³€ê²½ ì „ ì¥ì• ë¬¼ ìœ ë¬´ í™•ì¸
                    # if avoidance_direction == "RIGHT":
                    #     scan = current_lidar_data[225:270]
                    # else:
                    #     scan = current_lidar_data[90:130]

                    # # 10m ì´ë‚´ì˜ ì¥ì• ë¬¼ì´ 5ê°œ ì´ìƒì´ë©´ íšŒí”¼ ë¶ˆê°€
                    # close_points = [d for d in scan if np.isfinite(d) and d < 10]
                    # print(f"[ğŸ” {avoidance_direction} SCAN] ì´ {len(scan)}ê°œ ì¤‘ 10m ì´ë‚´ {len(close_points)}ê°œ")
                    # if len(close_points) >= 1000:
                    #     print(f"[âŒ íšŒí”¼ ë¶ˆê°€] {avoidance_direction} ì°¨ì„ ì— ì¥ì• ë¬¼ ìˆìŒ â†’ ì •ì§€ ë˜ëŠ” ëŒ€ê¸°")
                    #     target_speed = 50  # ì •ì§€
                    # else:
                    print(f"[âœ… íšŒí”¼ ê°€ëŠ¥] {avoidance_direction} ì°¨ì„ ìœ¼ë¡œ ë³€ê²½ ì‹œë„")
                    last_avoidance_time = time.time()
                    current_mission_state = "VEHICLE_AVOIDANCE"
                    avoidance_start_time = time.time()
                    last_avoidance_time = time.time() 
                
                elif obstacle_state == "SLOW":
                    target_speed = 50

            drive(target_angle, target_speed)
        
        elif current_mission_state == "CONE_NAVIGATION":
            # ë¼ë°”ì½˜ ì‚¬ì´ ì¡°í–¥ê° ê³„ì‚°
            cone_angle = calculate_cone_steering_camera(current_image_data, prev_angle, False)
            prev_angle = cone_angle
            cone_visible = detect_cones_only_camera(current_image_data)
            print(f"[STATE] ğŸŸ§ ë¼ë°”ì½˜ ì‚¬ì´ ì£¼í–‰ ì¤‘ (angle: {cone_angle:.2f})")
            target_angle = cone_angle
            target_speed = 10  # ê°ì† ì£¼í–‰
            drive(target_angle, target_speed)

            if not detect_cone_presence(current_image_data, current_lidar_data) and not cone_visible:
                print("[STATE] ë¼ë°”ì½˜ ê°ì§€ ì•ˆë¨ â†’ LANE_FOLLOWING ë³µê·€")
                current_mission_state = "LANE_FOLLOWING"
                cone_navigation_start_time = None
                continue

        elif current_mission_state == "VEHICLE_AVOIDANCE":
            avoidance_angle = 25 if avoidance_direction == "RIGHT" else -25
            drive(avoidance_angle, 50)

            if time.time() - avoidance_start_time > 1.5:
                print("[íšŒí”¼ ì™„ë£Œ] â†’ ì°¨ì„  ì£¼í–‰ ë³µê·€")
                current_mission_state = "LANE_FOLLOWING"
                
                
        # LiDAR ê±°ë¦¬ ì •ë³´ ë””ë²„ê¹… ì¶œë ¥ (20ë„ ê°„ê²©)
        # if current_lidar_data is not None:
        #     bin_size = 20
        #     total_bins = 360 // bin_size
        #     print("ğŸ“¡ LiDAR 20ë„ ë‹¨ìœ„ ê°ì§€ ê°œìˆ˜:", end=' ')
        #     for i in range(total_bins):
        #         start = i * bin_size
        #         end = start + bin_size
        #         segment = current_lidar_data[start:end]
        #         count = len([d for d in segment if np.isfinite(d) and d < 30])
        #         print(f"{start:03d}Â°~{end:03d}Â°:{count:2d}", end=' | ')
        #     print()

        if current_lidar_data is not None:
            angles_rad = np.linspace(0, 2*np.pi, len(current_lidar_data))
            valid_indices = np.isfinite(current_lidar_data) & (current_lidar_data < 10)
            valid_ranges = current_lidar_data[valid_indices]
            valid_angles = angles_rad[valid_indices]
            
            x_coords = -valid_ranges * np.cos(valid_angles - np.pi / 2)
            y_coords = -valid_ranges * np.sin(valid_angles - np.pi / 2)
            
            # ì‹œê°í™”
            # lidar_points.set_data(x_coords, y_coords)
            # fig.canvas.draw_idle()
            # plt.pause(0.01)
            
            # ê°’ ì¶œë ¥
            avg_distance = np.mean(valid_ranges)
            # print(f"[INFO] Average LIDAR Distance: {avg_distance:.2f}m")
        # ========================================
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì´ë¯¸ì§€ ë° ë¼ì´ë‹¤ ì‹œê°í™”
        # ========================================
        if current_image_data.size > 0:
            cv2.putText(current_image_data, f"State: {current_mission_state}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            cv2.putText(current_image_data, f"Angle: {target_angle:.1f}, Speed: {target_speed:.1f}", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            cv2.putText(current_image_data, f"Lane Position: {lane_position}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)
            cv2.imshow("Current View (BGR)", current_image_data) # ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ 
            # gray_display = cv2.cvtColor(current_image_data, cv2.COLOR_BGR2GRAY)
            # cv2.imshow("Current View (Gray)", gray_display) # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ í‘œì‹œ 
            
        if cv2.waitKey(1) & 0xFF == ord('q'): # q í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
            break
        
        loop_rate.sleep() # ë£¨í”„ ì£¼ê¸° ìœ ì§€

    # ì¢…ë£Œ ì „ ëª¨í„° ì •ì§€
    drive(0,0)
    print("Program terminated. Stopping vehicle.")
    cv2.destroyAllWindows()
    if 'matplotlib' in sys.modules and plt.get_fignums():
        plt.ioff()
        plt.close(fig)


#=============================================
# ë©”ì¸í•¨ìˆ˜ í˜¸ì¶œ
# start() í•¨ìˆ˜ê°€ ì‹¤ì§ˆì ì¸ ë©”ì¸í•¨ìˆ˜
#=============================================
if __name__ == '__main__':
    import sys # sys ëª¨ë“ˆ import ì¶”ê°€
    start()