#!/usr/bin/env python
# -*- coding: utf-8 -*-
#=============================================
# ë³¸ í”„ë¡œê·¸ë¨ì€ 2025 ì œ8íšŒ êµ­ë¯¼ëŒ€ ììœ¨ì£¼í–‰ ê²½ì§„ëŒ€íšŒì—ì„œ
# ì˜ˆì„ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ íŒŒì¼ì…ë‹ˆë‹¤.
# ì˜ˆì„ ê³¼ì œ ìˆ˜í–‰ ìš©ë„ë¡œë§Œ ì‚¬ìš©ê°€ëŠ¥í•˜ë©° ì™¸ë¶€ìœ ì¶œì€ ê¸ˆì§€ë©ë‹ˆë‹¤.
#=============================================
# í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” ê°ì¢… íŒŒì´ì¬ íŒ¨í‚¤ì§€ë“¤ì˜ import ì„ ì–¸ë¶€
#=============================================
import numpy as np
import cv2, rospy, time, os, math
from sensor_msgs.msg import Image
from xycar_msgs.msg import XycarMotor
from cv_bridge import CvBridge
from sensor_msgs.msg import LaserScan
import matplotlib.pyplot as plt

#=============================================
# í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜, ì €ì¥ê³µê°„ ì„ ì–¸ë¶€
#=============================================
image = np.empty(shape=[0])  # ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë‹´ì„ ë³€ìˆ˜
ranges = None  # ë¼ì´ë‹¤ ë°ì´í„°ë¥¼ ë‹´ì„ ë³€ìˆ˜
motor = None  # ëª¨í„° ì œì–´ ROS Publisher
motor_msg = XycarMotor()  # ëª¨í„° í† í”½ ë©”ì‹œì§€
bridge = CvBridge()  # OpenCV í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¸Œë¦¿ì§€

# ì£¼í–‰ ìƒíƒœ ê´€ë ¨ ë³€ìˆ˜
# ê°€ëŠ¥í•œ ìƒíƒœ: "WAITING_FOR_GREEN_LIGHT", "LANE_FOLLOWING", "OBSTACLE_AVOIDANCE_RVC", "OBSTACLE_AVOIDANCE_VEHICLE"
current_mission_state = "WAITING_FOR_GREEN_LIGHT"
Lane_condition = 'n'
# ì°¨ëŸ‰ ì œì–´ ìƒìˆ˜
Fix_Speed = 50  # ê¸°ë³¸ ì£¼í–‰ ì†ë„. ìƒí™©ì— ë”°ë¼ ì¡°ì ˆ ê°€ëŠ¥ [cite: 129]
Slow_Speed = 20
Min_Speed = 5   # ìµœì†Œ ì£¼í–‰ ì†ë„ (ì˜ˆ: ì¥ì• ë¬¼ íšŒí”¼ ì‹œ)
Max_Speed = 100  # ìµœëŒ€ ì£¼í–‰ ì†ë„
Angle_Limit = 75 # ìµœëŒ€ ì¡°í–¥ê° (ì ˆëŒ€ê°’, xycar_motor í† í”½ì€ -100~100ì´ì§€ë§Œ ì‹¤ì œ ì°¨ëŸ‰ì€ +/-20ë„) [cite: 129]
prev_angle = 0.0

last_avoidance_time = 0  # ë§ˆì§€ë§‰ ì°¨ì„ ë³€ê²½ ì‹œê° ì €ì¥ìš© (ì´ˆ)
AVOIDANCE_COOLDOWN = 8   # ì¿¨íƒ€ì„ (ì´ˆ)

# ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ë³€ìˆ˜ (ì˜ˆì‹œ, ì‹¤ì œ ê°’ì€ íŠœë‹ í•„ìš”)
# ROI (Region of Interest) for traffic light (x, y, w, h) from top-left
TRAFFIC_LIGHT_ROI_INITIAL = (280, 100, 80, 150) # ì´ ê°’ë“¤ì€ ì‹œë®¬ë ˆì´í„° í™”ë©´ì— ë§ì¶° ì •ë°€í•˜ê²Œ íŠœë‹í•´ì•¼ í•©ë‹ˆë‹¤.
# HSV ìƒ‰ìƒ ë²”ìœ„ (Green, Yellow, Red) - ì‹¤ì œ ê°’ì€ íŠœë‹ í•„ìš”
GREEN_LOWER = np.array([40, 80, 80])
GREEN_UPPER = np.array([90, 255, 255])
YELLOW_LOWER = np.array([20, 100, 100])
YELLOW_UPPER = np.array([30, 255, 255])
RED_LOWER1 = np.array([0, 100, 100]) # ë¹¨ê°„ìƒ‰ì€ HSV ìƒ‰ê³µê°„ì—ì„œ ë‘ ë²”ìœ„ë¡œ ë‚˜ë‰  ìˆ˜ ìˆìŒ
RED_UPPER1 = np.array([10, 255, 255])
RED_LOWER2 = np.array([170, 100, 100])
RED_UPPER2 = np.array([180, 255, 255])

# ì°¨ì„  ê°ì§€ ROI (í™”ë©´ í•˜ë‹¨ ê¸°ì¤€, %ë¡œ ì„¤ì • í›„ ì ˆëŒ€ê°’ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥)
LANE_ROI_VERT_PERCENT_START = 0.6  # ì˜ˆ: í™”ë©´ ë†’ì´ì˜ 60% ì§€ì ë¶€í„°
LANE_ROI_VERT_PERCENT_END = 0.95   # ì˜ˆ: í™”ë©´ ë†’ì´ì˜ 95% ì§€ì ê¹Œì§€

#=============================================
# ë¼ì´ë‹¤ ìŠ¤ìº”ì •ë³´ë¡œ ê·¸ë¦¼ì„ ê·¸ë¦¬ê¸° ìœ„í•œ ë³€ìˆ˜ (ë””ë²„ê¹…ìš©)
#=============================================
#Competition guideline requests comments [cite: 153, 154, 155, 156]
#The following lines are for LIDAR visualization. May be commented out for performance.
fig, ax = plt.subplots(figsize=(8, 8))
ax.set_xlim(-10, 10) #LIDAR ìµœëŒ€ ê°ì§€ ê±°ë¦¬ê°€ 100m ì´ë‚˜, ì‹¤ì œ ì£¼í–‰ì— ì¤‘ìš”í•œ ì˜ì—­ ìœ„ì£¼ë¡œ í‘œì‹œ [cite: 118]
ax.set_ylim(-10, 10)
ax.set_aspect('equal')
lidar_points, = ax.plot([], [], 'bo', markersize=2)

#=============================================
# ì½œë°±í•¨ìˆ˜ - ì¹´ë©”ë¼ í† í”½ì„ ì²˜ë¦¬í•˜ëŠ” ì½œë°±í•¨ìˆ˜
# ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ image ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤. [cite: 115]
#=============================================
def usbcam_callback(data):
    global image
    image = bridge.imgmsg_to_cv2(data, "bgr8") # ROS Image ë©”ì‹œì§€ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜ [cite: 115]

#=============================================
# ì½œë°±í•¨ìˆ˜ - ë¼ì´ë‹¤ í† í”½ì„ ë°›ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” ì½œë°±í•¨ìˆ˜
# ë¼ì´ë‹¤ ë°ì´í„°ë¥¼ ë°›ì•„ ranges ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤. [cite: 119]
#=============================================
def lidar_callback(data):
    global ranges
    # 0-359ë„ ë°ì´í„°ë¥¼ ì‚¬ìš©, í•„ìš”ì‹œ íŠ¹ì • ê°ë„ ë²”ìœ„ë§Œ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì • ê°€ëŠ¥ [cite: 118]
    ranges = np.array(data.ranges)

#=============================================
# ëª¨í„°ë¡œ í† í”½ì„ ë°œí–‰í•˜ëŠ” í•¨ìˆ˜
# ì£¼ì–´ì§„ ê°ë„(angle)ì™€ ì†ë„(speed)ë¡œ ì°¨ëŸ‰ì„ ì œì–´í•©ë‹ˆë‹¤. [cite: 127, 130]
#=============================================
def drive(angle, speed):
    # ì¡°í–¥ê°ê³¼ ì†ë„ ì œí•œ
    motor_msg.angle = max(min(float(angle), Angle_Limit), -Angle_Limit)
    motor_msg.speed = max(min(float(speed), Max_Speed), -Max_Speed) # í›„ì§„ë„ ê³ ë ¤ì‹œ -Max_Speed
    motor.publish(motor_msg)

#=============================================
# ì‹ í˜¸ë“± ì¸ì‹ í•¨ìˆ˜
# ì…ë ¥: í˜„ì¬ ì¹´ë©”ë¼ ì´ë¯¸ì§€ (BGR)
# ì¶œë ¥: "RED", "YELLOW", "GREEN", ë˜ëŠ” "NONE"
# ì´ í•¨ìˆ˜ëŠ” ì‹¤ì œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ì±„ì›Œì ¸ì•¼ í•©ë‹ˆë‹¤. [cite: 134, 138]
#=============================================
def detect_traffic_light(current_image):
    # í•¨ìˆ˜ ì‹œì‘ ì‹œì ì— ì£¼ì„ ì¶”ê°€: ì´ í•¨ìˆ˜ëŠ” ì‹ í˜¸ë“±ì˜ ìƒ‰ìƒì„ ê°ì§€í•©ë‹ˆë‹¤.
    if current_image.size == 0:
        return "NONE"

    # 1. ê´€ì‹¬ ì˜ì—­(ROI) ì„¤ì • [cite: 114] (ì˜ˆì‹œ, ì‹¤ì œ ê°’ì€ íŠœë‹ í•„ìš”)
    # í™”ë©´ í¬ê¸°ì— ë”°ë¼ ROIë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •í•˜ê±°ë‚˜, ì—¬ëŸ¬ ê°œì˜ ROIë¥¼ ê²€ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    height, width = current_image.shape[:2]
    # ì˜ˆì‹œ ROI, ì‹¤ì œ ì¢Œí‘œëŠ” ì°¨ëŸ‰ì˜ ì¹´ë©”ë¼ ë·°ì™€ ì‹œë®¬ë ˆì´í„°ì— ë”°ë¼ ë‹¬ë¼ì§
    x, y, w, h = int(width*0.4), int(height*0.1), int(width*0.2), int(height*0.3) # ì¤‘ì•™ ìƒë‹¨ ì˜ì—­ìœ¼ë¡œ ê°€ì •
    # TRAFFIC_LIGHT_ROI_INITIAL ê°’ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ
    # x,y,w,h = TRAFFIC_LIGHT_ROI_INITIAL

    # ROIê°€ ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ì¡°ì •
    x = max(0, x)
    y = max(0, y)
    w = min(w, width - x)
    h = min(h, height - y)
    
    if w <= 0 or h <= 0:
        return "NONE" # ROIê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ

    roi = current_image[y:y+h, x:x+w]

    # 2. HSV ìƒ‰ ê³µê°„ìœ¼ë¡œ ë³€í™˜
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    # 3. ìƒ‰ìƒ ë§ˆìŠ¤í¬ ìƒì„± ë° ë¹› ê°ì§€
    # ê° ìƒ‰ìƒ(ë¹¨ê°•, ë…¸ë‘, ì´ˆë¡)ì— ëŒ€í•œ ë§ˆìŠ¤í¬ë¥¼ ë§Œë“­ë‹ˆë‹¤. [cite: 138]
    # ì˜ˆ: ì´ˆë¡ìƒ‰ ê°ì§€
    mask_green = cv2.inRange(hsv, GREEN_LOWER, GREEN_UPPER)
    # ì˜ˆ: ë…¸ë€ìƒ‰ ê°ì§€
    mask_yellow = cv2.inRange(hsv, YELLOW_LOWER, YELLOW_UPPER)
    # ì˜ˆ: ë¹¨ê°„ìƒ‰ ê°ì§€ (ë‘ ë²”ìœ„ ì¡°í•©)
    mask_red1 = cv2.inRange(hsv, RED_LOWER1, RED_UPPER1)
    mask_red2 = cv2.inRange(hsv, RED_LOWER2, RED_UPPER2)
    mask_red = cv2.bitwise_or(mask_red1, mask_red2)

    # 4. ê°€ì¥ ë‘ë“œëŸ¬ì§€ëŠ” ìƒ‰ìƒ íŒë‹¨
    # ê° ë§ˆìŠ¤í¬ì—ì„œ 0ì´ ì•„ë‹Œ í”½ì…€ ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì–´ë–¤ ìƒ‰ì´ ê°€ì¥ ë§ì´ ê²€ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
    # ë˜ëŠ” ì› ê²€ì¶œ(HoughCircles) ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì‹ í˜¸ë“±ì˜ ê° ë“± ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ê³  í•´ë‹¹ ì˜ì—­ì˜ ìƒ‰ìƒì„ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì´ ë¶€ë¶„ì€ ë”ìš± ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ì´ í•„ìš”í•©ë‹ˆë‹¤.
    # (ì˜ˆì‹œ: ë‹¨ìˆœíˆ í”½ì…€ ìˆ˜ë¡œ ë¹„êµ)
    green_pixels = cv2.countNonZero(mask_green)
    yellow_pixels = cv2.countNonZero(mask_yellow)
    red_pixels = cv2.countNonZero(mask_red)
    
    #cv2.imshow("Traffic Light ROI", roi) # ë””ë²„ê¹…ìš©
    #cv2.imshow("Green Mask", mask_green) # ë””ë²„ê¹…ìš©

    # ì„ê³„ê°’ ì„¤ì • (ì˜ˆ: ìµœì†Œ 100 í”½ì…€ ì´ìƒ ê°ì§€ë˜ì–´ì•¼ ìœ íš¨í•œ ì‹ í˜¸ë¡œ íŒë‹¨)
    min_pixel_threshold = 50 # ì´ ê°’ì€ íŠœë‹ í•„ìš”

    if green_pixels > min_pixel_threshold and green_pixels > yellow_pixels and green_pixels > red_pixels:
        # print("Traffic Light: GREEN")
        return "GREEN"
    elif yellow_pixels > min_pixel_threshold and yellow_pixels > green_pixels and yellow_pixels > red_pixels:
        # print("Traffic Light: YELLOW")
        return "YELLOW"
    elif red_pixels > min_pixel_threshold and red_pixels > green_pixels and red_pixels > yellow_pixels:
        # print("Traffic Light: RED")
        return "RED"
    
    return "NONE" # ê°ì§€ ì‹¤íŒ¨

#=============================================
# ì°¨ëŸ‰ ìœ„ì¹˜ íŒë‹¨
#=============================================
def detect_yellow_lane_side(image, left_lines, right_lines):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    yellow_range = (15, 50)  # Hue ê¸°ì¤€

    def yellow_ratio_along_lines(lines):
        yellow_count = 0
        total_count = 0

        for x1, y1, x2, y2 in lines:
            num_points = 10
            for i in range(num_points):
                x = int(x1 + (x2 - x1) * i / (num_points - 1))
                y = int(y1 + (y2 - y1) * i / (num_points - 1))
                if 0 <= x < hsv.shape[1] and 0 <= y < hsv.shape[0]:
                    hue = hsv[y, x, 0]
                    if yellow_range[0] <= hue <= yellow_range[1]:
                        yellow_count += 1
                    total_count += 1

        if total_count == 0:
            return 0.0
        return yellow_count / total_count

    left_yellow_ratio = yellow_ratio_along_lines(left_lines)
    right_yellow_ratio = yellow_ratio_along_lines(right_lines)

    # print(f"[Hue ë¶„ì„] ì™¼ìª½ ë…¸ë€ìƒ‰ ë¹„ìœ¨: {left_yellow_ratio:.2f}, ì˜¤ë¥¸ìª½: {right_yellow_ratio:.2f}")

    if left_yellow_ratio > right_yellow_ratio and left_yellow_ratio > 0.1:
        return "Right Lane"  # ì¤‘ì•™ì„ ì´ ì™¼ìª½ì— ìˆìŒ â†’ ìš°ì¸¡ ì°¨ì„  ì£¼í–‰ ì¤‘
    elif right_yellow_ratio > left_yellow_ratio and right_yellow_ratio > 0.1:
        return "Left Lane"   # ì¤‘ì•™ì„ ì´ ì˜¤ë¥¸ìª½ì— ìˆìŒ â†’ ì¢Œì¸¡ ì°¨ì„  ì£¼í–‰ ì¤‘
    else:
        return "Unknown"


#=============================================
# ì°¨ì„  ì¸ì‹ ë° ì¡°í–¥ê° ê³„ì‚° í•¨ìˆ˜
# ì…ë ¥: í˜„ì¬ ì¹´ë©”ë¼ ì´ë¯¸ì§€ (BGR)
# ì¶œë ¥: ê³„ì‚°ëœ ì¡°í–¥ê° (-Angle_Limit ~ +Angle_Limit)
# ì´ í•¨ìˆ˜ëŠ” ì‹¤ì œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ì±„ì›Œì ¸ì•¼ í•©ë‹ˆë‹¤. [cite: 135, 139]
#=============================================
def calculate_lane_steering(current_image):
    global Lane_condition
    # í•¨ìˆ˜ ì‹œì‘ ì‹œì ì— ì£¼ì„ ì¶”ê°€: ì´ í•¨ìˆ˜ëŠ” ì°¨ì„ ì„ ê°ì§€í•˜ê³  ì£¼í–‰ì„ ìœ„í•œ ì¡°í–¥ê°ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    if current_image.size == 0:
        return 0.0

    # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ê·¸ë ˆì´ìŠ¤ì¼€ì¼, ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬, ROI ì„¤ì • ë“±)
    height, width = current_image.shape[:2]
    gray = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY) # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ [cite: 115]
    blur = cv2.GaussianBlur(gray, (5, 5), 0)

    # ROI ì„¤ì •: í™”ë©´ í•˜ë‹¨ ì˜ì—­ë§Œ ì‚¬ìš© [cite: 135]
    roi_start_y = int(height * LANE_ROI_VERT_PERCENT_START)
    roi_end_y = int(height * LANE_ROI_VERT_PERCENT_END)
    # ì‚¬ë‹¤ë¦¬ê¼´ ROIë¥¼ ë§Œë“¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ì‚¬ê°í˜• ROIë¥¼ ì˜ˆì‹œë¡œ í•©ë‹ˆë‹¤.
    roi_mask = np.zeros_like(blur)
    #cv2.rectangle(roi_mask, (0, roi_start_y), (width-1, roi_end_y), 255, -1) # ì‚¬ê°í˜• ROI
    # ì¢€ ë” ì •êµí•œ ì‚¬ë‹¤ë¦¬ê¼´ ROI (ì˜ˆì‹œ)
    poly_vertices = np.array([[(0, roi_end_y), (width*0.1, roi_start_y), (width*0.9, roi_start_y), (width, roi_end_y)]], dtype=np.int32)
    cv2.fillPoly(roi_mask, poly_vertices, 255)
    
    masked_image = cv2.bitwise_and(blur, roi_mask)
    #cv2.imshow("Lane ROI", masked_image) # ë””ë²„ê¹…ìš©

    # 2. ì—£ì§€ ê²€ì¶œ (Canny)
    edges = cv2.Canny(masked_image, 70, 140) # ì„ê³„ê°’ì€ íŠœë‹ í•„ìš”
    # cv2.imshow("Lane Edges", edges) # ë””ë²„ê¹…ìš©

    # 3. í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ì„ ë¶„ ê²€ì¶œ ë˜ëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹
    # ì´ ë¶€ë¶„ì€ ì°¨ì„  ê°ì§€ ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ì…ë‹ˆë‹¤.
    # ì˜ˆì‹œ: í—ˆí”„ ì„  ë³€í™˜ (ì„ ë¶„ë“¤ì˜ í‰ê·  ê¸°ìš¸ê¸°ì™€ ìœ„ì¹˜ë¥¼ ì´ìš©í•´ ì¢Œìš° ì°¨ì„  ëŒ€í‘œì„  ê³„ì‚°)
    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=30, minLineLength=20, maxLineGap=20) # íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”

    if lines is None:
        return 0.0 # ì°¨ì„  ë¯¸ê²€ì¶œ ì‹œ ì§ì§„

    # 4. ê²€ì¶œëœ ì„ ë“¤ì„ ì´ìš©í•´ ì¢Œ/ìš° ì°¨ì„  ëŒ€í‘œì„  ê³„ì‚° ë° í™”ë©´ ì¤‘ì•™ê³¼ì˜ ì˜¤ì°¨ ê³„ì‚°
    # (ì´ ë¶€ë¶„ì€ ë§¤ìš° ë³µì¡í•˜ë©°, ë§ì€ ì˜ˆì™¸ ì²˜ë¦¬ì™€ ì •êµí•œ ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤)
    # ì˜ˆë¥¼ ë“¤ì–´, ì„ ë“¤ì˜ ê¸°ìš¸ê¸°ë¥¼ ì´ìš©í•´ ì¢Œì¸¡ì„ ê³¼ ìš°ì¸¡ì„ ì„ êµ¬ë¶„í•˜ê³ ,
    # ê° ì„ ë“¤ì˜ í‰ê·  ìœ„ì¹˜ë¥¼ êµ¬í•´ ì°¨ì„  ì¤‘ì•™ì„ ì¶”ì •í•©ë‹ˆë‹¤.
    # í™”ë©´ ì¤‘ì•™ (width / 2)ê³¼ ì°¨ì„  ì¤‘ì•™ ê°„ì˜ ì˜¤í”„ì…‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    # ì˜¤í”„ì…‹ì— ë¹„ë¡€í•˜ëŠ” ì¡°í–¥ê°ì„ ì„¤ì •í•©ë‹ˆë‹¤ (PID ì œì–´ê¸° ì‚¬ìš© ê°€ëŠ¥).
    
    # --- ì´ ì•„ë˜ëŠ” ë§¤ìš° ê°„ëµí™”ëœ ì˜ˆì‹œ ë¡œì§ì…ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” í›¨ì”¬ ì •êµí•´ì•¼ í•©ë‹ˆë‹¤. ---
    left_lines, right_lines = [], []
    for line in lines:
        x1, y1, x2, y2 = line[0]
        if x2 - x1 == 0: # ìˆ˜ì§ì„  ë°©ì§€
            slope = np.inf
        else:
            slope = (y2 - y1) / (x2 - x1)
        
        if slope < -0.3: # ì¢Œì¸¡ ì°¨ì„  (ê¸°ìš¸ê¸° ìŒìˆ˜) - ê°’ íŠœë‹ í•„ìš”
            left_lines.append(line[0])
        elif slope > 0.3: # ìš°ì¸¡ ì°¨ì„  (ê¸°ìš¸ê¸° ì–‘ìˆ˜) - ê°’ íŠœë‹ í•„ìš”
            right_lines.append(line[0])

    # ëŒ€í‘œì„  ê³„ì‚° (ë§¤ìš° ê°„ì†Œí™”ëœ ë²„ì „)
    # ì‹¤ì œë¡œëŠ” ì„ ë“¤ì„ í”¼íŒ…í•˜ì—¬ yì¢Œí‘œì— ë”°ë¥¸ xì¢Œí‘œë¥¼ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ xì¢Œí‘œì˜ í‰ê· ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    # ì¢Œì¸¡ ì°¨ì„ ì´ ì¸ì‹ëœ ê²½ìš°
    if left_lines:
        left_x_coords = []
        for x1,y1,x2,y2 in left_lines:
            left_x_coords.extend([x1,x2])
        avg_left_x = np.mean(left_x_coords)
    else: # ì¢Œì¸¡ ì°¨ì„ ì´ ì•ˆë³´ì´ë©´ í™”ë©´ ì¢Œì¸¡ ëìœ¼ë¡œ ê°€ì • (ë°©ì–´ì )
        avg_left_x = width * 0.1 

    # ìš°ì¸¡ ì°¨ì„ ì´ ì¸ì‹ëœ ê²½ìš°
    if right_lines:
        right_x_coords = []
        for x1,y1,x2,y2 in right_lines:
            right_x_coords.extend([x1,x2])
        avg_right_x = np.mean(right_x_coords)
    else: # ìš°ì¸¡ ì°¨ì„ ì´ ì•ˆë³´ì´ë©´ í™”ë©´ ìš°ì¸¡ ëìœ¼ë¡œ ê°€ì • (ë°©ì–´ì )
        avg_right_x = width * 0.9

    lane_center_x = (avg_left_x + avg_right_x) / 2.0
    car_center_x = width / 2.0
    
    # ì˜¤ì°¨ ê³„ì‚° (í™”ë©´ ì¤‘ì•™ê³¼ ì°¨ì„  ì¤‘ì•™ ê°„ì˜ í”½ì…€ ì°¨ì´)
    error = lane_center_x - car_center_x

    # 5. ì¡°í–¥ê° ê³„ì‚° (P ì œì–´ê¸° ì˜ˆì‹œ)
    # Kp ê°’ì€ íŠœë‹ì„ í†µí•´ ìµœì ê°’ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
    # error ê°’ì˜ ìŠ¤ì¼€ì¼ì„ ì¡°í–¥ê° ë²”ìœ„(-Angle_Limit ~ Angle_Limit)ì— ë§ê²Œ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    Kp = 0.4 # ì˜ˆì‹œ ê°’. (Angle_Limit / (width/2)) ì™€ ìœ ì‚¬í•œ ìŠ¤ì¼€ì¼ë¡œ ì¡°ì •
    steering_angle = Kp * error
    
    # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
    debug_image = current_image.copy()

    # ì¢Œì¸¡ ì°¨ì„  ì„ ë¶„ì€ íŒŒë€ìƒ‰ìœ¼ë¡œ
    for x1, y1, x2, y2 in left_lines:
        cv2.line(current_image, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Blue
    # ìš°ì¸¡ ì°¨ì„  ì„ ë¶„ì€ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ
    for x1, y1, x2, y2 in right_lines:
        cv2.line(current_image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red

    # ROI ì„ ë„ ì¶”ê°€ë¡œ ì‹œê°í™” (ì„ íƒì‚¬í•­)
    cv2.polylines(current_image, [poly_vertices], isClosed=True, color=(0, 255, 0), thickness=2)


    # ìƒ‰ìƒ ë¶„ì„ (ë…¸ë€ìƒ‰ì€ Hue 20~30 ì‚¬ì´)
    lane_position = detect_yellow_lane_side(debug_image, left_lines, right_lines)
    # visualize_yellow_area(current_image)  # ì„ íƒì‚¬í•­

        
    # ê³„ì‚°ëœ ì¡°í–¥ê° ë°˜í™˜ (drive í•¨ìˆ˜ì—ì„œ ìµœì¢… ì œí•œ)    
    return steering_angle, lane_position


def visualize_yellow_area(image_bgr):
    hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
    hue = hsv[:, :, 0]
    yellow_mask = cv2.inRange(hue, 15, 50)

    yellow_highlight = image_bgr.copy()
    yellow_highlight[yellow_mask > 0] = [0, 0, 255]
    cv2.imshow("Yellow Lane Highlight", yellow_highlight)
    cv2.waitKey(1)


#=============================================
# ë¼ë°”ì½˜ ê°ì§€
#=============================================
def detect_cone_presence(current_image, lidar_data):
    if lidar_data is None or current_image.size == 0:
        return False

    # 1. LiDAR ê¸°ì¤€ ìœ íš¨í•œ ê±°ë¦¬ê°’ ì¶”ì¶œ
    front_left = lidar_data[340:]
    front_right = lidar_data[:21]
    front_scan = np.concatenate((front_left, front_right))
    front_scan = np.array(front_scan)
    valid_lidar = front_scan[np.isfinite(front_scan) & (front_scan > 0.5) & (front_scan < 10.0)]

    # 2. 5ê°œ ì´ìƒ ê°ì§€ëœ ê²½ìš°ì—ë§Œ ì¹´ë©”ë¼ íŒë‹¨ ìˆ˜í–‰
    if len(valid_lidar) < 5:
        return False

    height = current_image.shape[0]
    roi = current_image[int(height * 0.6):, :]

    # 3. ì¹´ë©”ë¼ì—ì„œ ë¼ë°”ì½˜ ìƒ‰ìƒ(Hue â‰ˆ 8) í•„í„°ë§
    hsv = cv2.cvtColor(current_image, cv2.COLOR_BGR2HSV)
    LOWER_CONE = np.array([5, 80, 150])
    UPPER_CONE = np.array([15, 255, 255])
    mask = cv2.inRange(hsv, LOWER_CONE, UPPER_CONE)

    # 4. ì—£ì§€(ìœ¤ê³½ì„ ) ê²€ì¶œ
    edges = cv2.Canny(mask, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # 5. ì¼ì • í¬ê¸° ì´ìƒì˜ ìœ¤ê³½ì„ ì´ ì¡´ì¬í•˜ë©´ ë¼ë°”ì½˜ìœ¼ë¡œ íŒë‹¨
    for cnt in contours:
        if cv2.contourArea(cnt) > 100:  # 100ì€ ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)
            return True

    return False

def detect_cones_only_camera(image):
    height, width = image.shape[:2]
    roi = image[int(height * 0.6):, :]  # í•˜ë‹¨ 40% ì‚¬ìš©
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    LOWER_CONE = np.array([5, 80, 150])
    UPPER_CONE = np.array([15, 255, 255])
    mask = cv2.inRange(hsv, LOWER_CONE, UPPER_CONE)

    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # ì¼ì • í¬ê¸° ì´ìƒì˜ ë¼ë°”ì½˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    return any(cv2.contourArea(cnt) > 100 for cnt in contours)


#=============================================
# ë¼ë°”ì½˜ ì£¼í–‰í–‰
#=============================================
# ì „ì—­ ìƒíƒœ ë³€ìˆ˜
def calculate_cone_steering_camera(image, prev_angle=0, debug=False):

    if image is None or image.size == 0:
        return prev_angle

    height, width = image.shape[:2]
    roi_start = int(height * 0.7)
    roi = image[roi_start:, :]

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    LOWER_ORANGE = np.array([5, 100, 100])
    UPPER_ORANGE = np.array([20, 255, 255])
    mask = cv2.inRange(hsv, LOWER_ORANGE, UPPER_ORANGE)

    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    centers = []

    # ì¤‘ì•™ ë¬´ì‹œ ì˜ì—­ ì •ì˜ (45%~55%)
    center_ignore_min = int(width * 0.45)
    center_ignore_max = int(width * 0.55)

    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 150:
            M = cv2.moments(cnt)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                # ì¤‘ì•™ ì˜ì—­ ë¬´ì‹œ
                if center_ignore_min <= cx <= center_ignore_max:
                    continue
                centers.append((cx, cy))

    vis = roi.copy()
    left = []
    right = []
    for cx, cy in centers:
        if cx < width // 2:
            left.append(cx)
            cv2.circle(vis, (cx, cy), 5, (255, 0, 0), -1)
        else:
            right.append(cx)
            cv2.circle(vis, (cx, cy), 5, (0, 0, 255), -1)


    angle = prev_angle

    if len(left) > 0 and len(right) > 0:
        left_x = min(left)
        right_x = max(right)
        gap = right_x - left_x

        if gap < 350:
            if debug: print(f"[CAMERA] ë¼ë°”ì½˜ ê°„ê²© {gap}px < 350 â†’ ì´ì „ ê°ë„ ìœ ì§€")
        else:
            mid_x = (left_x + right_x) // 2
            error = mid_x - width // 2
            angle = np.clip(0.6 * error, -40, 40)
            if debug:
                print(f"[CAMERA] ì¤‘ì•™: {mid_x}, ê°„ê²©: {gap}, ì¡°í–¥: {angle:.2f}")
                cv2.line(vis, (mid_x, 0), (mid_x, vis.shape[0]), (0, 255, 0), 2)
                cv2.line(vis, (width // 2, 0), (width // 2, vis.shape[0]), (0, 255, 255), 2)

    elif len(left) > 0:
        left_x = min(left)
        angle = 70
        if debug: print("[CAMERA] ì™¼ìª½ ë¼ë°”ì½˜ë§Œ ê°ì§€ â†’ ìš°íšŒì „")

    elif len(right) > 0:
        right_x = max(right)
        angle = -70
        if debug: print("[CAMERA] ì˜¤ë¥¸ìª½ ë¼ë°”ì½˜ë§Œ ê°ì§€ â†’ ì¢ŒíšŒì „")

    else:
        if debug: print("[CAMERA] ë¼ë°”ì½˜ ì—†ìŒ â†’ ì´ì „ ê°ë„ ìœ ì§€")

    if debug:
        cv2.imshow("Cone Detection (camera)", vis)
        cv2.rectangle(vis, (center_ignore_min, 0), (center_ignore_max, vis.shape[0]), (0, 255, 255), 2)
        cv2.waitKey(1)

    return angle



#=============================================
# ì°¨ëŸ‰ íŒë‹¨ í•¨ìˆ˜
#=============================================
def detect_vehicle_front(lidar_data):
    if lidar_data is None or len(lidar_data) < 360:
        return "CLEAR"

    front_left = lidar_data[355:]
    front_right = lidar_data[:6]
    front_scan = np.concatenate((front_left, front_right))

    front_scan = np.array(front_scan)
    valid = front_scan[np.isfinite(front_scan) & (front_scan > 1.0) & (front_scan < 20.0)]

    if len(valid) == 0:
        return "CLEAR"

    # ì—°ì† ê°ì§€ êµ¬ê°„ ê³„ì‚°
    close_flags = (front_scan > 1.0) & (front_scan < 20.0)
    consecutive_count = 0
    max_consecutive = 0

    for val in close_flags:
        if val:
            consecutive_count += 1
            max_consecutive = max(max_consecutive, consecutive_count)
        else:
            consecutive_count = 0

    print(f"[ì „ë°© ê°ì§€] ìœ íš¨ ê±°ë¦¬ {len(valid)}ê°œ / ì—°ì† {max_consecutive}ê°œ")

    # ğŸš— ì°¨ëŸ‰ìœ¼ë¡œ íŒë‹¨ (ì™„ì „ ì •ì§€)
    if max_consecutive >= 8:
        return "STOP"

    # ğŸ¢ ê°ì§€ëŠ” ëì§€ë§Œ í™•ì‹  ë¶€ì¡± (ê°ì†)
    elif len(valid) >= 5:
        return "SLOW"

    return "CLEAR"

#=============================================
# ì‹¤ì§ˆì ì¸ ë©”ì¸ í•¨ìˆ˜
#=============================================
def start():
    global motor, image, ranges, current_mission_state, prev_angle, last_avoidance_time
    lane_position = "Unknown"
    print("Start program --------------")

    #=========================================
    # ë…¸ë“œë¥¼ ìƒì„±í•˜ê³ , êµ¬ë…/ë°œí–‰í•  í† í”½ë“¤ì„ ì„ ì–¸í•©ë‹ˆë‹¤.
    #=========================================
    rospy.init_node('Track_Driver') # ë…¸ë“œ ì´ë¦„ ì´ˆê¸°í™”
    # ì¹´ë©”ë¼ í† í”½ êµ¬ë… [cite: 114]
    rospy.Subscriber("/usb_cam/image_raw/",Image,usbcam_callback, queue_size=1)
    # ë¼ì´ë‹¤ í† í”½ êµ¬ë… [cite: 118]
    rospy.Subscriber("/scan", LaserScan, lidar_callback, queue_size=1)
    # ëª¨í„° ì œì–´ í† í”½ ë°œí–‰ [cite: 127]
    motor = rospy.Publisher('xycar_motor', XycarMotor, queue_size=1)
        
    #=========================================
    # ë…¸ë“œë“¤ë¡œë¶€í„° ì²«ë²ˆì§¸ í† í”½ë“¤ì´ ë„ì°©í•  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    #=========================================
    print("Waiting for first messages...")
    rospy.wait_for_message("/usb_cam/image_raw/", Image) # ì¹´ë©”ë¼ ì¤€ë¹„ ëŒ€ê¸° [cite: 115]
    print("Camera Ready --------------")
    rospy.wait_for_message("/scan", LaserScan) # ë¼ì´ë‹¤ ì¤€ë¹„ ëŒ€ê¸° [cite: 119]
    print("Lidar Ready --------------")
    
    #=========================================
    # ë¼ì´ë‹¤ ìŠ¤ìº”ì •ë³´ì— ëŒ€í•œ ì‹œê°í™” ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤. (ë””ë²„ê¹…ìš©)
    #=========================================
    #Competition guideline requests comments [cite: 153, 154, 155, 156]
    if 'matplotlib' in sys.modules: # matplotlib ì‚¬ìš© ê°€ëŠ¥í•  ë•Œë§Œ
        plt.ion() # ëŒ€í™”í˜• ëª¨ë“œ ì¼œê¸°
        plt.show()
        print("Lidar Visualizer Ready (matplotlib) ----------")
    else:
        print("Matplotlib not available for Lidar visualization.")

    
    print("======================================")
    print(" S T A R T    D R I V I N G ...")
    print("======================================")

    #=========================================
    # ë©”ì¸ ë£¨í”„ 
    # ë£¨í”„ ì£¼ê¸° ì„¤ì • (ì˜ˆ: 0.1ì´ˆ = 10Hz)
    #=========================================
    loop_rate = rospy.Rate(10) # 10 Hz

    while not rospy.is_shutdown():
        # í˜„ì¬ ì´ë¯¸ì§€ì™€ ë¼ì´ë‹¤ ë°ì´í„° ë³µì‚¬ (ì½œë°±ì—ì„œ ë³€ê²½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        current_image_data = image.copy()
        current_lidar_data = ranges.copy() if ranges is not None else None

        # ì¡°í–¥ê°ê³¼ ì†ë„ ì´ˆê¸°í™”
        target_angle = 0.0
        target_speed = 0.0

        # ========================================
        # ì£¼í–‰ ìƒíƒœì— ë”°ë¥¸ ë¡œì§ ë¶„ê¸°
        # ========================================
        if current_mission_state == "WAITING_FOR_GREEN_LIGHT":
            # ì´ ë¸”ë¡ì€ ì‹ í˜¸ë“±ì´ ë…¹ìƒ‰ì´ ë  ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ëŠ” ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. [cite: 134, 138]
            traffic_light_color = detect_traffic_light(current_image_data)
            # print(f"STATE: WAITING_FOR_GREEN_LIGHT, Detected: {traffic_light_color}")
            if traffic_light_color == "GREEN":
                print("Green light detected! Starting lane following.")
                current_mission_state = "LANE_FOLLOWING"
                target_speed = Fix_Speed # ì¶œë°œ ì†ë„
            elif traffic_light_color == "YELLOW" or traffic_light_color == "RED":
                target_speed = 0 # ì •ì§€
            else: # "NONE" or other
                target_speed = 0 # ì‹ í˜¸ ë¯¸ì¸ì‹ ì‹œ ì •ì§€

        elif current_mission_state == "LANE_FOLLOWING":
            # ì´ ë¸”ë¡ì€ ì°¨ì„ ì„ ë”°ë¼ ì£¼í–‰í•˜ëŠ” ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. [cite: 135, 139]
            # print("STATE: LANE_FOLLOWING")
            target_angle, lane_position = calculate_lane_steering(current_image_data)
            target_speed = Fix_Speed

            # ë¼ë°”ì½˜ ê°ì§€ ì‹œ ìƒíƒœ ì „í™˜
            if detect_cone_presence(current_image_data, current_lidar_data):
                print("[STATE] ğŸŸ§ ë¼ë°”ì½˜ ì¸ì‹ë¨ â†’ ìƒíƒœ ì „í™˜: CONE_NAVIGATION")
                current_mission_state = "CONE_NAVIGATION"

            # ì°¨ëŸ‰ ê°ì§€ ì¡°ê±´ ì¶”ê°€
            if current_lidar_data is not None:
                obstacle_state = detect_vehicle_front(current_lidar_data)
                if obstacle_state == "STOP":
                        # ì¿¨íƒ€ì„ ì²´í¬
                    if time.time() - last_avoidance_time < AVOIDANCE_COOLDOWN:
                        print("[â³ ì¿¨íƒ€ì„] ìµœê·¼ íšŒí”¼ ì´í›„ ëŒ€ê¸° ì¤‘ â†’ ì°¨ì„  ìœ ì§€")
                        continue  # ìƒíƒœ ì „í™˜ ì•ˆ í•˜ê³  ì°¨ì„  ìœ ì§€

                    print("[STATE] ğŸš— ì°¨ëŸ‰ ê°ì§€ â†’ ì°¨ì„ ë³€ê²½")
                    # avoidance_start_time = time.time()

                    if lane_position == "Left Lane":
                        avoidance_direction = "RIGHT"
                    elif lane_position == "Right Lane":
                        avoidance_direction = "LEFT"
                    else:
                        # ì°¨ì„  ì •ë³´ ë¶ˆë¶„ëª… ì‹œ ê¸°ë³¸ íšŒí”¼ ë°©í–¥ ì„¤ì •
                        avoidance_direction = "RIGHT"


                    # ì°¨ì„  ë³€ê²½ ì „ ì¥ì• ë¬¼ ìœ ë¬´ í™•ì¸
                    if avoidance_direction == "RIGHT":
                        scan = current_lidar_data[225:270]
                    else:
                        scan = current_lidar_data[90:130]

                    # 10m ì´ë‚´ì˜ ì¥ì• ë¬¼ì´ 5ê°œ ì´ìƒì´ë©´ íšŒí”¼ ë¶ˆê°€
                    close_points = [d for d in scan if np.isfinite(d) and d < 10]
                    print(f"[ğŸ” {avoidance_direction} SCAN] ì´ {len(scan)}ê°œ ì¤‘ 10m ì´ë‚´ {len(close_points)}ê°œ")
                    if len(close_points) >= 1000:
                        print(f"[âŒ íšŒí”¼ ë¶ˆê°€] {avoidance_direction} ì°¨ì„ ì— ì¥ì• ë¬¼ ìˆìŒ â†’ ì •ì§€ ë˜ëŠ” ëŒ€ê¸°")
                        target_speed = 50  # ì •ì§€
                    else:
                        print(f"[âœ… íšŒí”¼ ê°€ëŠ¥] {avoidance_direction} ì°¨ì„ ìœ¼ë¡œ ë³€ê²½ ì‹œë„")
                        last_avoidance_time = time.time()
                        current_mission_state = "VEHICLE_AVOIDANCE"
                        avoidance_start_time = time.time()
                        last_avoidance_time = time.time() 


            drive(target_angle, target_speed)
        
        elif current_mission_state == "CONE_NAVIGATION":
            # ë¼ë°”ì½˜ ì‚¬ì´ ì¡°í–¥ê° ê³„ì‚°
            cone_angle = calculate_cone_steering_camera(current_image_data, prev_angle, True)
            prev_angle = cone_angle
            cone_visible = detect_cones_only_camera(current_image_data)
            print(f"[STATE] ğŸŸ§ ë¼ë°”ì½˜ ì‚¬ì´ ì£¼í–‰ ì¤‘ (angle: {cone_angle:.2f})")
            target_angle = cone_angle
            target_speed = 10  # ê°ì† ì£¼í–‰
            drive(target_angle, target_speed)

            if not detect_cone_presence(current_image_data, current_lidar_data) and not cone_visible:
                print("[STATE] ë¼ë°”ì½˜ ê°ì§€ ì•ˆë¨ â†’ LANE_FOLLOWING ë³µê·€")
                current_mission_state = "LANE_FOLLOWING"
                cone_navigation_start_time = None
                continue

        elif current_mission_state == "VEHICLE_AVOIDANCE":
            avoidance_angle = 25 if avoidance_direction == "RIGHT" else -25
            drive(avoidance_angle, 50)

            if time.time() - avoidance_start_time > 1.5:
                print("[íšŒí”¼ ì™„ë£Œ] â†’ ì°¨ì„  ì£¼í–‰ ë³µê·€")
                current_mission_state = "LANE_FOLLOWING"
                
                
        # LiDAR ê±°ë¦¬ ì •ë³´ ë””ë²„ê¹… ì¶œë ¥ (20ë„ ê°„ê²©)
        # if current_lidar_data is not None:
        #     bin_size = 20
        #     total_bins = 360 // bin_size
        #     print("ğŸ“¡ LiDAR 20ë„ ë‹¨ìœ„ ê°ì§€ ê°œìˆ˜:", end=' ')
        #     for i in range(total_bins):
        #         start = i * bin_size
        #         end = start + bin_size
        #         segment = current_lidar_data[start:end]
        #         count = len([d for d in segment if np.isfinite(d) and d < 30])
        #         print(f"{start:03d}Â°~{end:03d}Â°:{count:2d}", end=' | ')
        #     print()

        if current_lidar_data is not None:
            angles_rad = np.linspace(0, 2*np.pi, len(current_lidar_data))
            valid_indices = np.isfinite(current_lidar_data) & (current_lidar_data < 10)
            valid_ranges = current_lidar_data[valid_indices]
            valid_angles = angles_rad[valid_indices]
            
            x_coords = -valid_ranges * np.cos(valid_angles - np.pi / 2)
            y_coords = -valid_ranges * np.sin(valid_angles - np.pi / 2)
            
            # ì‹œê°í™”
            lidar_points.set_data(x_coords, y_coords)
            fig.canvas.draw_idle()
            plt.pause(0.01)
            
            # ê°’ ì¶œë ¥
            avg_distance = np.mean(valid_ranges)
            # print(f"[INFO] Average LIDAR Distance: {avg_distance:.2f}m")
        # ========================================
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì´ë¯¸ì§€ ë° ë¼ì´ë‹¤ ì‹œê°í™”
        # ========================================
        if current_image_data.size > 0:
            cv2.putText(current_image_data, f"State: {current_mission_state}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            cv2.putText(current_image_data, f"Angle: {target_angle:.1f}, Speed: {target_speed:.1f}", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            cv2.putText(current_image_data, f"Lane Position: {lane_position}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)
            cv2.imshow("Current View (BGR)", current_image_data) # ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ [cite: 115]
            # gray_display = cv2.cvtColor(current_image_data, cv2.COLOR_BGR2GRAY)
            # cv2.imshow("Current View (Gray)", gray_display) # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ í‘œì‹œ [cite: 115]
            
        if cv2.waitKey(1) & 0xFF == ord('q'): # q í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
            break
        
        loop_rate.sleep() # ë£¨í”„ ì£¼ê¸° ìœ ì§€

    # ì¢…ë£Œ ì „ ëª¨í„° ì •ì§€
    drive(0,0)
    print("Program terminated. Stopping vehicle.")
    cv2.destroyAllWindows()
    if 'matplotlib' in sys.modules and plt.get_fignums():
        plt.ioff()
        plt.close(fig)


#=============================================
# ë©”ì¸í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
# start() í•¨ìˆ˜ê°€ ì‹¤ì§ˆì ì¸ ë©”ì¸í•¨ìˆ˜ì…ë‹ˆë‹¤.
#=============================================
if __name__ == '__main__':
    # ì „ì—­ë³€ìˆ˜ matplotlib ê´€ë ¨ ì´ˆê¸°í™”
    # ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ plt ê°ì²´ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•¨
    # (start í•¨ìˆ˜ ë‚´ë¶€ë¡œ ì˜®ê¸°ê±°ë‚˜, í˜¹ì€ ì—¬ê¸°ì„œ ì—ëŸ¬ í•¸ë“¤ë§ì„ í•´ì£¼ëŠ” ê²ƒì´ ì¢‹ìŒ)
    import sys # sys ëª¨ë“ˆ import ì¶”ê°€
    if 'matplotlib' in sys.modules:
        try:
            # GUI ë°±ì—”ë“œ ì„¤ì • (WSL í™˜ê²½ ë“±ì—ì„œ í•„ìš”í•  ìˆ˜ ìˆìŒ)
            # import matplotlib
            # matplotlib.use('TkAgg') # ë˜ëŠ” 'Qt5Agg' ë“±
            pass
        except ImportError:
            print("Matplotlib GUI backend error. Visualization might not work.")
            # matplotlib ì‚¬ìš© ë¶ˆê°€ ì²˜ë¦¬
            del fig, ax, lidar_points # ê´€ë ¨ ë³€ìˆ˜ ì‚­ì œ
            sys.modules.pop('matplotlib.pyplot', None)
            sys.modules.pop('matplotlib', None)


    start()